---
title: "Homework 6"
author: "Pooja Mukund"
date: "11/26/2021"
output: github_document
---

```{r}
#Load relevant libraries

library(tidyverse)
library(viridis)
library(modelr)
library(mgcv)
```

```{r}
#Setup for visualizations
knitr::opts_chunk$set(
  fig.width = 10,
  fig.asp = .6,
  out.width = "90%"
)
```

## Load Data
```{r}
birth<- read_csv("data/birthweight.csv")
```

## Data Cleaning   

First we will check if there are any NAs in columns 
```{r warning=FALSE}
# Check for NAs 
birth%>%
summarise_all(funs(sum(is.na(.)))) # No NAs in columns 
```
From the data description in homework assignment we know that `babysex`, `frace`, `malform`, `mrace` are all categorical variables that are currently coded numerically. We will first change this to categorical variables.  

```{r}
birth%>%
  summarise_all(class)
#All coded numerically 

birth%>%
  distinct(frace)
#Only 5 categories - 1, 2, 3, 4, 8 even though description has 9 there are no 9s that exist in this current dataset 

birth%>%
  distinct(mrace)
#Only 1, 2, 3, 4 for mrace

birth%>%
  distinct(malform)

birth_cln<-birth%>%
  mutate( babysex = replace(babysex, babysex == 1, "Male"),
          babysex = replace(babysex, babysex == 2, "Female"), 
          frace = replace(frace, frace ==1, "White"),
          frace = replace(frace, frace ==2, "Black"),
          frace = replace(frace, frace ==3, "Asian"),
          frace = replace(frace, frace ==4, "Puerto Rican"),
          frace = replace(frace, frace ==8, "Other"),
          malform = as.logical(malform), 
          mrace = replace(mrace, mrace ==1, "White"),
          mrace = replace(mrace, mrace ==2, "Black"),
          mrace = replace(mrace, mrace ==3, "Asian"),
          mrace = replace(mrace, mrace ==4, "Puerto Rican"), 
          babysex = factor(babysex, levels=c("Male", "Female")), 
          frace = factor(frace, levels=c("White", "Black", "Asian", "Puerto Rican", "Other")),
          mrace = factor(mrace, levels=c("White", "Black", "Asian", "Puerto Rican")))

birth_cln%>%
  head(5)%>%
  knitr::kable()
```

## Regression model for birthweight

From this [publication](https://pubmed.ncbi.nlm.nih.gov/7570074/), I hypothesize that maternal race, infant sex, maternal smoking status, and education would be important factors for birthweight. Since we do not have education, I will use family monthly income (`fincome`) as a proxy for education. The World Health Organization (WHO) defines smoking status as "someone who smokes a tobacco product either daily or occasionally". I will use `smoken` and create a new variable `smoke_status` defined by smoker as greater than 0 cigarettes per day and non-smoker as 0 cigarettes per day.  


```{r}
#Create smoker variable 
birth_cln%>%
  distinct(smoken)

birth_cln<-birth_cln%>%
  mutate(smoke_status = case_when(smoken >0 ~ "smoker",
                                  smoken ==0 ~"non-smoker"))
```


## Model Fitting Process

We will start with `smoke_status` and `babysex` and evaluate based on Adjusted $R^2$ 

```{r}
fit = lm(bwt ~ smoke_status + babysex + gaweeks, data = birth_cln)
summary(fit)$adj.r.squared

fit%>%
  broom::tidy()%>%
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)
```

With this model, we start out with a $R^2$ of 0.1912. In our regression table, we can also see that all predictors are statistically significant. 


Let's see if adding maternal race helps this model 
```{r}
fit_2 = lm(bwt ~ smoke_status + babysex + mrace + gaweeks, data = birth_cln)
summary(fit_2)$adj.r.squared

fit_2%>%
  broom::tidy()%>%
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)

```

This slightly increased our Adjusted $R^2$ from 0.1912 to 0.2467. Again, all our predictors are statistically significant. Let's see if adding family monthly income helps (`fincome`). 

```{r}
fit_3 = lm(bwt ~ smoke_status + babysex + mrace+fincome +gaweeks, data = birth_cln)
summary(fit_3)$adj.r.squared

fit_3%>%  
  broom::tidy()%>%
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)
```

This slightly increased our Adjusted $R^2$ from 0.2467 to 0.2468. Still not the best model, this may suggest a linear model is not the best fit for birthweight. In this model, we can also see that `fincome` is not statistically significant. However, for the purpose of this assignment, we will continue using `fit_3`. 

```{r}
birth_cln %>% 
  modelr::add_residuals(fit_3) %>% 
  modelr::add_predictions(fit_3)%>%
  ggplot(aes(x = bwt, y = resid)) +geom_point()


birth_cln %>% 
  modelr::add_residuals(fit_3) %>% 
  modelr::add_predictions(fit_3)%>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point()+ geom_hline(yintercept=0, linetype="dashed", color = "grey")+
  ylab("Prediction Value") + xlab("Residual Value") + ggtitle("Model Predictions against Residual Values")
```

The Residuals vs. Predicted Values plot is used to detect unequal variance (heteroscedasticity) and outliers. We are looking to see that residual values bounce around 0 and no unusual values stand out from the pattern, which is an indication of no outliers. Based on the plot of predictions against residual, the third model created looks like there is a pretty good fit.     


## Compare your model to two others:

  * One using length at birth and gestational age as predictors (main effects only) - `model_comp_1`
  
  * One using head circumference, length, sex, and all interactions (including the three-way interaction) between these - `model_comp_2`. 

```{r}
model_comp_1 = lm(bwt ~ blength + gaweeks, data = birth_cln)
summary(model_comp_1)$adj.r.squared
model_comp_1%>%
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)

model_comp_2 = lm(bwt ~ blength + bhead +babysex + bhead*blength*babysex, data = birth_cln)
summary(model_comp_2)$adj.r.squared

model_comp_2%>%
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)
```

## Compare using cross-validation 
```{r}
cv_df =
  crossv_mc(birth_cln, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(
    model_1  = map(train, ~lm(bwt ~ smoke_status + babysex + mrace+fincome +gaweeks, data = .x)),
    model_2     = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_3  = map(train, ~lm(bwt ~ blength + bhead +babysex + bhead*blength*babysex, data = .x))) %>% 
  mutate(
    rmse_1 = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
    rmse_2    = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)),
    rmse_3 = map2_dbl(model_3, test, ~rmse(model = .x, data = .y)))

```

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() + xlab("Model") + ylab("RMSE Score")
```
Model 3 seems to be the best fit and model 1, the model I created, seems to be the worst fit. The RMSE of Model 1 is the highest and RMSE of Model 3 is the lowest.  It is possible there are too many variables in model 1 and this is reducing the predictability of the model. Also the variables chosen in my model, are likely not as important as the variables in the other two models. This suggests that head circumference, length at birth, and baby sex are important variables for prediction of birthweight and income, maternal race, and smoking status are not as important. Model 2 had the least amount of predictors so it is possible the model is too simple which would explain the lower RMSE. 

## Problem 2 
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r}
weather_fit<-lm(tmax ~ tmin, data = weather_df)

log(weather_fit$coefficients[2]*weather_fit$coefficients[1])

lm(tmax ~ tmin, data = weather_df) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)

broom::glance(weather_fit)%>%
  select(r.squared)
```
## 5000 Sample Bootstrap for estimates 

```{r warning = FALSE}
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

boot_straps = 
  data_frame(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )

boot_straps

bootstrap_results = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy),
    summary = map(models, broom::glance))%>% 
  unnest(results)%>%
  select(term, estimate, summary)%>%
  unnest(summary)%>%
  select(term, estimate, r.squared)%>%
  pivot_wider(names_from = term,
              values_from = estimate)

bootstrap_results%>%
  mutate(log_b0_b1 = `(Intercept)` *tmin)%>%
  pivot_longer(cols = c("r.squared","log_b0_b1"),
               names_to = "quantity",
               values_to = "estimate")%>%
  select(quantity, estimate)%>%
  group_by(quantity) %>% 
  summarize(
    ci_lower = quantile(estimate, 0.025), 
    ci_upper = quantile(estimate, 0.975))%>%
  knitr::kable()
  
  
  
  

```

Let's plot the distribution of the estimates. First look at the distribution for $R^2$. 

```{r}
#Density plot for R-Squared 
bootstrap_results%>%
  mutate(log_b0_b1 = `(Intercept)` *tmin)%>%
  ggplot(aes(x = r.squared)) + geom_density()+xlab(expression(R^2))+ylab("Density")
```

Now let's look at the distribution plot for $log(\hat{\beta}_{0}*\hat{\beta}_{1})$
```{r}
bootstrap_results%>%
  mutate(log_b0_b1 = `(Intercept)` *tmin)%>%
  ggplot(aes(x = log_b0_b1)) + geom_density() +xlab(expression(log(hat(beta[0])%*%hat(beta[1]))))+ylab("Density")
```

