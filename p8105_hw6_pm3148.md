Homework 6
================
Pooja Mukund
11/26/2021

``` r
#Load relevant libraries

library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──

    ## ✓ ggplot2 3.3.5     ✓ purrr   0.3.4
    ## ✓ tibble  3.1.5     ✓ dplyr   1.0.7
    ## ✓ tidyr   1.1.3     ✓ stringr 1.4.0
    ## ✓ readr   2.0.1     ✓ forcats 0.5.1

    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(viridis)
```

    ## Loading required package: viridisLite

``` r
library(modelr)
library(mgcv)
```

    ## Loading required package: nlme

    ## 
    ## Attaching package: 'nlme'

    ## The following object is masked from 'package:dplyr':
    ## 
    ##     collapse

    ## This is mgcv 1.8-38. For overview type 'help("mgcv-package")'.

``` r
#Setup for visualizations
knitr::opts_chunk$set(
  fig.width = 10,
  fig.asp = .6,
  out.width = "90%"
)
```

## Load Data

``` r
birth<- read_csv("data/birthweight.csv")
```

    ## Rows: 4342 Columns: 20

    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (20): babysex, bhead, blength, bwt, delwt, fincome, frace, gaweeks, malf...

    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Data Cleaning

First we will check if there are any NAs in columns

``` r
# Check for NAs 
birth%>%
summarise_all(funs(sum(is.na(.)))) # No NAs in columns 
```

    ## # A tibble: 1 × 20
    ##   babysex bhead blength   bwt delwt fincome frace gaweeks malform menarche
    ##     <int> <int>   <int> <int> <int>   <int> <int>   <int>   <int>    <int>
    ## 1       0     0       0     0     0       0     0       0       0        0
    ## # … with 10 more variables: mheight <int>, momage <int>, mrace <int>,
    ## #   parity <int>, pnumlbw <int>, pnumsga <int>, ppbmi <int>, ppwt <int>,
    ## #   smoken <int>, wtgain <int>

From the data description in homework assignment we know that `babysex`,
`frace`, `malform`, `mrace` are all categorical variables that are
currently coded numerically. We will first change this to categorical
variables.

``` r
birth%>%
  summarise_all(class)
```

    ## # A tibble: 1 × 20
    ##   babysex bhead   blength bwt     delwt   fincome frace gaweeks malform menarche
    ##   <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <chr> <chr>   <chr>   <chr>   
    ## 1 numeric numeric numeric numeric numeric numeric nume… numeric numeric numeric 
    ## # … with 10 more variables: mheight <chr>, momage <chr>, mrace <chr>,
    ## #   parity <chr>, pnumlbw <chr>, pnumsga <chr>, ppbmi <chr>, ppwt <chr>,
    ## #   smoken <chr>, wtgain <chr>

``` r
#All coded numerically 

birth%>%
  distinct(frace)
```

    ## # A tibble: 5 × 1
    ##   frace
    ##   <dbl>
    ## 1     1
    ## 2     2
    ## 3     3
    ## 4     4
    ## 5     8

``` r
#Only 5 categories - 1, 2, 3, 4, 8 even though description has 9 there are no 9s that exist in this current dataset 

birth%>%
  distinct(mrace)
```

    ## # A tibble: 4 × 1
    ##   mrace
    ##   <dbl>
    ## 1     1
    ## 2     2
    ## 3     3
    ## 4     4

``` r
#Only 1, 2, 3, 4 for mrace

birth%>%
  distinct(malform)
```

    ## # A tibble: 2 × 1
    ##   malform
    ##     <dbl>
    ## 1       0
    ## 2       1

``` r
birth_cln<-birth%>%
  mutate( babysex = replace(babysex, babysex == 1, "Male"),
          babysex = replace(babysex, babysex == 2, "Female"), 
          frace = replace(frace, frace ==1, "White"),
          frace = replace(frace, frace ==2, "Black"),
          frace = replace(frace, frace ==3, "Asian"),
          frace = replace(frace, frace ==4, "Puerto Rican"),
          frace = replace(frace, frace ==8, "Other"),
          malform = as.logical(malform), 
          mrace = replace(mrace, mrace ==1, "White"),
          mrace = replace(mrace, mrace ==2, "Black"),
          mrace = replace(mrace, mrace ==3, "Asian"),
          mrace = replace(mrace, mrace ==4, "Puerto Rican"), 
          babysex = factor(babysex, levels=c("Male", "Female")), 
          frace = factor(frace, levels=c("White", "Black", "Asian", "Puerto Rican", "Other")),
          mrace = factor(mrace, levels=c("White", "Black", "Asian", "Puerto Rican")))

birth_cln%>%
  head(5)%>%
  knitr::kable()
```

| babysex | bhead | blength |  bwt | delwt | fincome | frace | gaweeks | malform | menarche | mheight | momage | mrace | parity | pnumlbw | pnumsga |    ppbmi | ppwt | smoken | wtgain |
|:--------|------:|--------:|-----:|------:|--------:|:------|--------:|:--------|---------:|--------:|-------:|:------|-------:|--------:|--------:|---------:|-----:|-------:|-------:|
| Female  |    34 |      51 | 3629 |   177 |      35 | White |    39.9 | FALSE   |       13 |      63 |     36 | White |      3 |       0 |       0 | 26.27184 |  148 |      0 |     29 |
| Male    |    34 |      48 | 3062 |   156 |      65 | Black |    25.9 | FALSE   |       14 |      65 |     25 | Black |      0 |       0 |       0 | 21.34485 |  128 |      0 |     28 |
| Female  |    36 |      50 | 3345 |   148 |      85 | White |    39.9 | FALSE   |       12 |      64 |     29 | White |      0 |       0 |       0 | 23.56517 |  137 |      1 |     11 |
| Male    |    34 |      52 | 3062 |   157 |      55 | White |    40.0 | FALSE   |       14 |      64 |     18 | White |      0 |       0 |       0 | 21.84508 |  127 |     10 |     30 |
| Female  |    34 |      52 | 3374 |   156 |       5 | White |    41.6 | FALSE   |       13 |      66 |     20 | White |      0 |       0 |       0 | 21.02642 |  130 |      1 |     26 |

## Regression model for birthweight

From this [publication](https://pubmed.ncbi.nlm.nih.gov/7570074/), I
hypothesize that maternal race, infant sex, maternal smoking status, and
education would be important factors for birthweight. Since we do not
have education, I will use family monthly income (`fincome`) as a proxy
for education. The World Health Organization (WHO) defines smoking
status as “someone who smokes a tobacco product either daily or
occasionally”. I will use `smoken` and create a new variable
`smoke_status` defined by smoker as greater than 0 cigarettes per day
and non-smoker as 0 cigarettes per day.

``` r
#Create smoker variable 
birth_cln%>%
  distinct(smoken)
```

    ## # A tibble: 33 × 1
    ##    smoken
    ##     <dbl>
    ##  1  0    
    ##  2  1    
    ##  3 10    
    ##  4  4    
    ##  5  0.125
    ##  6 15    
    ##  7  8    
    ##  8  5    
    ##  9 20    
    ## 10  3    
    ## # … with 23 more rows

``` r
birth_cln<-birth_cln%>%
  mutate(smoke_status = case_when(smoken >0 ~ "smoker",
                                  smoken ==0 ~"non-smoker"))
```

## Model Fitting Process

We will start with `smoke_status` and `babysex` and evaluate based on
Adjusted *R*<sup>2</sup>

``` r
fit = lm(bwt ~ smoke_status + babysex + gaweeks, data = birth_cln)
summary(fit)$adj.r.squared
```

    ## [1] 0.1912056

``` r
fit%>%
  broom::tidy()%>%
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)
```

| term                | estimate | p.value |
|:--------------------|---------:|--------:|
| (Intercept)         |  559.373 |       0 |
| smoke\_statussmoker | -117.996 |       0 |
| babysexFemale       | -102.009 |       0 |
| gaweeks             |   67.298 |       0 |

With this model, we start out with a *R*<sup>2</sup> of 0.1912. In our
regression table, we can also see that all predictors are statistically
significant.

Let’s see if adding maternal race helps this model

``` r
fit_2 = lm(bwt ~ smoke_status + babysex + mrace + gaweeks, data = birth_cln)
summary(fit_2)$adj.r.squared
```

    ## [1] 0.2467065

``` r
fit_2%>%
  broom::tidy()%>%
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)
```

| term                | estimate | p.value |
|:--------------------|---------:|--------:|
| (Intercept)         |  976.891 |   0.000 |
| smoke\_statussmoker | -143.119 |   0.000 |
| babysexFemale       |  -95.798 |   0.000 |
| mraceBlack          | -255.850 |   0.000 |
| mraceAsian          | -186.612 |   0.007 |
| mracePuerto Rican   | -163.360 |   0.000 |
| gaweeks             |   60.026 |   0.000 |

This slightly increased our Adjusted *R*<sup>2</sup> from 0.1912 to
0.2467. Again, all our predictors are statistically significant. Let’s
see if adding family monthly income helps (`fincome`).

``` r
fit_3 = lm(bwt ~ smoke_status + babysex + mrace+fincome +gaweeks, data = birth_cln)
summary(fit_3)$adj.r.squared
```

    ## [1] 0.2468899

``` r
fit_3%>%  
  broom::tidy()%>%
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)
```

| term                | estimate | p.value |
|:--------------------|---------:|--------:|
| (Intercept)         |  958.684 |   0.000 |
| smoke\_statussmoker | -142.278 |   0.000 |
| babysexFemale       |  -95.521 |   0.000 |
| mraceBlack          | -247.336 |   0.000 |
| mraceAsian          | -182.030 |   0.008 |
| mracePuerto Rican   | -155.796 |   0.000 |
| fincome             |    0.407 |   0.152 |
| gaweeks             |   59.913 |   0.000 |

This slightly increased our Adjusted *R*<sup>2</sup> from 0.2467 to
0.2468. Still not the best model, this may suggest a linear model is not
the best fit for birthweight. In this model, we can also see that
`fincome` is not statistically significant. However, for the purpose of
this assignment, we will continue using `fit_3`.

``` r
birth_cln %>% 
  modelr::add_residuals(fit_3) %>% 
  modelr::add_predictions(fit_3)%>%
  ggplot(aes(x = bwt, y = resid)) +geom_point()
```

<img src="p8105_hw6_pm3148_files/figure-gfm/unnamed-chunk-10-1.png" width="90%" />

``` r
birth_cln %>% 
  modelr::add_residuals(fit_3) %>% 
  modelr::add_predictions(fit_3)%>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point()+ geom_hline(yintercept=0, linetype="dashed", color = "grey")+
  ylab("Prediction Value") + xlab("Residual Value") + ggtitle("Model Predictions against Residual Values")
```

<img src="p8105_hw6_pm3148_files/figure-gfm/unnamed-chunk-10-2.png" width="90%" />

The Residuals vs. Predicted Values plot is used to detect unequal
variance (heteroscedasticity) and outliers. We are looking to see that
residual values bounce around 0 and no unusual values stand out from the
pattern, which is an indication of no outliers. Based on the plot of
predictions against residual, the third model created looks like there
is a pretty good fit.

## Compare your model to two others:

-   One using length at birth and gestational age as predictors (main
    effects only) - `model_comp_1`

-   One using head circumference, length, sex, and all interactions
    (including the three-way interaction) between these -
    `model_comp_2`.

``` r
model_comp_1 = lm(bwt ~ blength + gaweeks, data = birth_cln)
summary(model_comp_1)$adj.r.squared
```

    ## [1] 0.5766943

``` r
model_comp_1%>%
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)
```

| term        |  estimate | p.value |
|:------------|----------:|--------:|
| (Intercept) | -4347.667 |       0 |
| blength     |   128.556 |       0 |
| gaweeks     |    27.047 |       0 |

``` r
model_comp_2 = lm(bwt ~ blength + bhead +babysex + bhead*blength*babysex, data = birth_cln)
summary(model_comp_2)$adj.r.squared
```

    ## [1] 0.684367

``` r
model_comp_2%>%
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)
```

| term                        |  estimate | p.value |
|:----------------------------|----------:|--------:|
| (Intercept)                 | -7176.817 |   0.000 |
| blength                     |   102.127 |   0.000 |
| bhead                       |   181.796 |   0.000 |
| babysexFemale               |  6374.868 |   0.000 |
| blength:bhead               |    -0.554 |   0.478 |
| bhead:babysexFemale         |  -198.393 |   0.000 |
| blength:babysexFemale       |  -123.773 |   0.000 |
| blength:bhead:babysexFemale |     3.878 |   0.000 |

## Compare using cross-validation

``` r
cv_df =
  crossv_mc(birth_cln, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(
    model_1  = map(train, ~lm(bwt ~ smoke_status + babysex + mrace+fincome +gaweeks, data = .x)),
    model_2     = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_3  = map(train, ~lm(bwt ~ blength + bhead +babysex + bhead*blength*babysex, data = .x))) %>% 
  mutate(
    rmse_1 = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
    rmse_2    = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)),
    rmse_3 = map2_dbl(model_3, test, ~rmse(model = .x, data = .y)))
```

``` r
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() + xlab("Model") + ylab("RMSE Score")
```

<img src="p8105_hw6_pm3148_files/figure-gfm/unnamed-chunk-13-1.png" width="90%" />
Model 3 seems to be the best fit and model 1, the model I created, seems
to be the worst fit. The RMSE of Model 1 is the highest and RMSE of
Model 3 is the lowest. It is possible there are too many variables in
model 1 and this is reducing the predictability of the model. Also the
variables chosen in my model, are likely not as important as the
variables in the other two models. This suggests that head
circumference, length at birth, and baby sex are important variables for
prediction of birthweight and income, maternal race, and smoking status
are not as important. Model 2 had the least amount of predictors so it
is possible the model is too simple which would explain the lower RMSE.

## Problem 2

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

    ## Registered S3 method overwritten by 'hoardr':
    ##   method           from
    ##   print.cache_info httr

    ## using cached file: ~/Library/Caches/R/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2021-10-05 10:30:21 (7.602)

    ## file min/max dates: 1869-01-01 / 2021-10-31

``` r
weather_fit<-lm(tmax ~ tmin, data = weather_df)

log(weather_fit$coefficients[2]*weather_fit$coefficients[1])
```

    ##     tmin 
    ## 2.013752

``` r
lm(tmax ~ tmin, data = weather_df) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```

| term        | estimate | std.error | statistic | p.value |
|:------------|---------:|----------:|----------:|--------:|
| (Intercept) |    7.209 |     0.226 |    31.847 |       0 |
| tmin        |    1.039 |     0.017 |    61.161 |       0 |

``` r
broom::glance(weather_fit)%>%
  select(r.squared)
```

    ## # A tibble: 1 × 1
    ##   r.squared
    ##       <dbl>
    ## 1     0.912

## 5000 Sample Bootstrap for estimates

``` r
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

boot_straps = 
  data_frame(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )

boot_straps
```

    ## # A tibble: 5,000 × 2
    ##    strap_number strap_sample      
    ##           <int> <list>            
    ##  1            1 <tibble [365 × 6]>
    ##  2            2 <tibble [365 × 6]>
    ##  3            3 <tibble [365 × 6]>
    ##  4            4 <tibble [365 × 6]>
    ##  5            5 <tibble [365 × 6]>
    ##  6            6 <tibble [365 × 6]>
    ##  7            7 <tibble [365 × 6]>
    ##  8            8 <tibble [365 × 6]>
    ##  9            9 <tibble [365 × 6]>
    ## 10           10 <tibble [365 × 6]>
    ## # … with 4,990 more rows

``` r
bootstrap_results = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy),
    summary = map(models, broom::glance))%>% 
  unnest(results)%>%
  select(term, estimate, summary)%>%
  unnest(summary)%>%
  select(term, estimate, r.squared)%>%
  pivot_wider(names_from = term,
              values_from = estimate)

bootstrap_results%>%
  mutate(log_b0_b1 = `(Intercept)` *tmin)%>%
  pivot_longer(cols = c("r.squared","log_b0_b1"),
               names_to = "quantity",
               values_to = "estimate")%>%
  select(quantity, estimate)%>%
  group_by(quantity) %>% 
  summarize(
    ci_lower = quantile(estimate, 0.025), 
    ci_upper = quantile(estimate, 0.975))%>%
  knitr::kable()
```

| quantity    | ci\_lower | ci\_upper |
|:------------|----------:|----------:|
| log\_b0\_b1 | 7.1435869 | 7.8356506 |
| r.squared   | 0.8938606 | 0.9272512 |

Let’s plot the distribution of the estimates. First look at the
distribution for *R*<sup>2</sup>.

``` r
#Density plot for R-Squared 
bootstrap_results%>%
  mutate(log_b0_b1 = `(Intercept)` *tmin)%>%
  ggplot(aes(x = r.squared)) + geom_density()+xlab(expression(R^2))+ylab("Density")
```

<img src="p8105_hw6_pm3148_files/figure-gfm/unnamed-chunk-17-1.png" width="90%" />
Distributions for *R*<sup>2</sup> is fairly uniform. This makes sense
because it is a sample of n = 5000 so we would expect a normal
distribution.

Now let’s look at the distribution plot for
*l**o**g*(*β̂*<sub>0</sub> \* *β̂*<sub>1</sub>)

``` r
bootstrap_results%>%
  mutate(log_b0_b1 = `(Intercept)` *tmin)%>%
  ggplot(aes(x = log_b0_b1)) + geom_density() +xlab(expression(log(hat(beta[0])%*%hat(beta[1]))))+ylab("Density")
```

<img src="p8105_hw6_pm3148_files/figure-gfm/unnamed-chunk-18-1.png" width="90%" />

The distribution for *l**o**g*(*β̂*<sub>0</sub> \* *β̂*<sub>1</sub>) is
also fairly normal.This makes sense because it is a sample of n = 5000
so we would expect a normal distribution.
